{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G81P4h-T-erA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a17738-c233-47f5-8250-4650bf05ef08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import semcor\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import math\n",
        "nltk.download(\"semcor\")\n",
        "nltk.download(\"universal_tagset\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "# corpus = semcor._items(None, \"token\", True, True, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "metadata": {
        "id": "cXhPL8_5ecj9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_wv = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IkHfzfHef_P",
        "outputId": "8d027912-99c7-447d-f03a-89bb7ab93b6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv_mean = 0\n",
        "wv_std = 1\n",
        "dim_wv = 300"
      ],
      "metadata": {
        "id": "-NCRQ4fkegdf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth = 200)"
      ],
      "metadata": {
        "id": "1Gc62ravP55W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = semcor.tagged_sents(tag = 'both')"
      ],
      "metadata": {
        "id": "6ohWX0-lTwHM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOpQwo_d9BcX",
        "outputId": "925884fb-e70a-48bb-a8e5-d109630767dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tree('DT', ['The']),\n",
              " Tree(Lemma('group.n.01.group'), [Tree('NE', [Tree('NNP', ['Fulton', 'County', 'Grand', 'Jury'])])]),\n",
              " Tree(Lemma('state.v.01.say'), [Tree('VB', ['said'])]),\n",
              " Tree(Lemma('friday.n.01.Friday'), [Tree('NN', ['Friday'])]),\n",
              " Tree('DT', ['an']),\n",
              " Tree(Lemma('probe.n.01.investigation'), [Tree('NN', ['investigation'])]),\n",
              " Tree('IN', ['of']),\n",
              " Tree(Lemma('atlanta.n.01.Atlanta'), [Tree('NN', ['Atlanta'])]),\n",
              " Tree('POS', [\"'s\"]),\n",
              " Tree(Lemma('late.s.03.recent'), [Tree('JJ', ['recent'])]),\n",
              " Tree(Lemma('primary.n.01.primary_election'), [Tree('NN', ['primary', 'election'])]),\n",
              " Tree(Lemma('produce.v.04.produce'), [Tree('VB', ['produced'])]),\n",
              " Tree(None, ['``']),\n",
              " Tree('DT', ['no']),\n",
              " Tree(Lemma('evidence.n.01.evidence'), [Tree('NN', ['evidence'])]),\n",
              " Tree(None, [\"''\"]),\n",
              " Tree('IN', ['that']),\n",
              " Tree('DT', ['any']),\n",
              " Tree(Lemma('abnormality.n.04.irregularity'), [Tree('NN', ['irregularities'])]),\n",
              " Tree(Lemma('happen.v.01.take_place'), [Tree('VB', ['took', 'place'])]),\n",
              " Tree(None, ['.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "\n",
        "def preprocess_from_semcor(sentence):\n",
        "  \"\"\"\n",
        "    input: a list ( an element of semcor.tagged_sents(tag='both') )\n",
        "    output: a list of (word, pos_tag, synset) triplets. synset may be None. omit words (which would be punctuations) whose pos_tag is None.\n",
        "  \"\"\"\n",
        "  context = []\n",
        "  for word in sentence:\n",
        "    \n",
        "    lemma = word.label()\n",
        "    \n",
        "    if type(lemma) != nltk.corpus.reader.wordnet.Lemma: # meaning word.label() is either None or a string (which may be pos_tag or synset name)\n",
        "      if lemma == None:\n",
        "        continue\n",
        "      if ('.' not in lemma):                            # label is pos tag\n",
        "        pos = lemma\n",
        "        if pos == 'NE':                                 # sometimes a named entity tree with no labelled synset/lemma is present. This is just to catch and ignore that case, NE is obviously not a pos tag\n",
        "          continue\n",
        "        ww = word[0].lower()\n",
        "        context.append((ww,pos,'None'))\n",
        "        continue\n",
        "      else:                                             # label is synset name\n",
        "        lemma_available = False\n",
        "    else:\n",
        "      lemma_available = True\n",
        "    \n",
        "    tree = word[0]\n",
        "    if tree.label() == 'NE':\n",
        "      tree = tree[0]\n",
        "    pos = tree.label()\n",
        "    \n",
        "    if lemma_available:\n",
        "      ww = lemma.name().lower()\n",
        "      synset = lemma.synset().name()\n",
        "    else:\n",
        "      ww = lemmatizer.lemmatize(tree[0], map.get(pos[0], wordnet.NOUN)).lower()\n",
        "      synset = lemma\n",
        "    \n",
        "    context.append((ww,pos,synset))\n",
        "\n",
        "  return context\n",
        "\n",
        "preprocess_from_semcor(semcor.tagged_sents(tag = 'both')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF3x6Ix1R4GY",
        "outputId": "b1566c1c-8fd6-4880-d2de-8661dc622301"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT', 'None'),\n",
              " ('group', 'NNP', 'group.n.01'),\n",
              " ('say', 'VB', 'state.v.01'),\n",
              " ('friday', 'NN', 'friday.n.01'),\n",
              " ('an', 'DT', 'None'),\n",
              " ('investigation', 'NN', 'probe.n.01'),\n",
              " ('of', 'IN', 'None'),\n",
              " ('atlanta', 'NN', 'atlanta.n.01'),\n",
              " (\"'s\", 'POS', 'None'),\n",
              " ('recent', 'JJ', 'late.s.03'),\n",
              " ('primary_election', 'NN', 'primary.n.01'),\n",
              " ('produce', 'VB', 'produce.v.04'),\n",
              " ('no', 'DT', 'None'),\n",
              " ('evidence', 'NN', 'evidence.n.01'),\n",
              " ('that', 'IN', 'None'),\n",
              " ('any', 'DT', 'None'),\n",
              " ('irregularity', 'NN', 'abnormality.n.04'),\n",
              " ('take_place', 'VB', 'happen.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "\n",
        "def preprocess(sentence, no_pos = False):\n",
        "  \"\"\"\n",
        "    input: sentence as a string\n",
        "    output: list of (lemmatized_word, pos) or (lemmatized_word) according to the bool argument no_pos\n",
        "  \"\"\"\n",
        "  tagged_sent = nltk.pos_tag(word_tokenize(sentence))\n",
        "  lemmatized_sent = [(lemmatizer.lemmatize(word, map.get(pos[0], wordnet.NOUN)).lower(), pos) for word, pos in tagged_sent]\n",
        "  if no_pos:\n",
        "    return [w for (w,p) in lemmatized_sent]\n",
        "  else:\n",
        "    return lemmatized_sent\n",
        "\n",
        "preprocess(\"The authorities said an investigation produced no evidence\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJywjyKkWpLT",
        "outputId": "8391b9be-1772-42a4-ffed-af12f5e2bf06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('authority', 'NNS'),\n",
              " ('say', 'VBD'),\n",
              " ('an', 'DT'),\n",
              " ('investigation', 'NN'),\n",
              " ('produce', 'VBD'),\n",
              " ('no', 'DT'),\n",
              " ('evidence', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for MFS\n",
        "\n",
        "word_to_synset_freq = dict()\n",
        "for i in range(10000):\n",
        "  sentence = corpus[i]\n",
        "  for (w,p,s) in preprocess_from_semcor(sentence):\n",
        "    if s == None:\n",
        "      continue\n",
        "    if w not in word_to_synset_freq:\n",
        "      word_to_synset_freq[w] = dict()\n",
        "    if s not in word_to_synset_freq[w]:\n",
        "      word_to_synset_freq[w][s] = 1\n",
        "    else:\n",
        "      word_to_synset_freq[w][s] += 1\n",
        "\n",
        "# word_to_synset_freq"
      ],
      "metadata": {
        "id": "D394hLiUnTJz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extended_lesk(synsets, context):\n",
        "  (maxsofar, best_ss) = (0, None)\n",
        "  for ss in synsets:\n",
        "    if ss.pos() != 'n':\n",
        "      continue\n",
        "    defn = preprocess(ss.definition(), no_pos = True)\n",
        "    for hypernym in ss.hypernyms():\n",
        "      defn += preprocess(hypernym.definition(), no_pos = True)\n",
        "    for hyponym in ss.hyponyms():\n",
        "      defn += preprocess(hyponym.definition(), no_pos = True)\n",
        "    \n",
        "    score = len(context.intersection(defn))\n",
        "    if score > maxsofar:\n",
        "      (maxsofar, best_ss) = (score, ss)\n",
        "  \n",
        "  if not best_ss: # no synset had any intersection with context\n",
        "    best_ss = synsets[0]  #wfs\n",
        "  \n",
        "  return best_ss"
      ],
      "metadata": {
        "id": "pBNHA1UvYB0E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pagerank(nouns, use_wv = False):\n",
        "  start, end = 0, 0\n",
        "  num_synsets = []\n",
        "  synset_lists = []\n",
        "  idx = []\n",
        "  for noun in nouns:\n",
        "    _synsets = wordnet.synsets(noun)\n",
        "    _synsets = [ss for ss in _synsets if ss.pos() == 'n']\n",
        "    num_synsets.append(len(_synsets))\n",
        "    synset_lists.append(_synsets)\n",
        "    end = start + len(_synsets)\n",
        "    idx.append((start,end))\n",
        "    start = end\n",
        "  W = np.zeros((end,end))\n",
        "\n",
        "  index_order = np.argsort(num_synsets)\n",
        "  for ii in range(len(index_order)-1):\n",
        "    ss_list1 = synset_lists[index_order[ii]]\n",
        "    start1, end1 = idx[index_order[ii]]\n",
        "    ss_list2 = synset_lists[index_order[ii+1]]\n",
        "    start2, end2 = idx[index_order[ii+1]]\n",
        "    for i in range(len(ss_list1)):\n",
        "      for j in range(len(ss_list2)):\n",
        "        defn_i = preprocess(ss_list1[i].definition(), no_pos = True)\n",
        "        defn_j = preprocess(ss_list2[j].definition(), no_pos = True)\n",
        "        if not use_wv:  # lesk based similarity\n",
        "          val = len(set(defn_j).intersection(defn_i))\n",
        "          W[start1+i][start2+j] = val\n",
        "          # val = len(set(defn_i).intersection(defn_j))\n",
        "          # W[start2+j][start1+i] = val\n",
        "        else:\n",
        "          wv_i = np.zeros((len(defn_i), dim_wv))\n",
        "          wv_j = np.zeros((len(defn_j), dim_wv))\n",
        "          for _index in range(len(defn_i)):\n",
        "            word = defn_i[_index]\n",
        "            if word in google_wv:\n",
        "              wv_i[_index] = google_wv[word]\n",
        "            else:\n",
        "              wv_i[_index] = np.random.normal(wv_mean,wv_std,dim_wv)\n",
        "          for _index in range(len(defn_j)):\n",
        "            word = defn_j[_index]\n",
        "            if word in google_wv:\n",
        "              wv_j[_index] = google_wv[word]\n",
        "            else:\n",
        "              wv_j[_index] = np.random.normal(wv_mean,wv_std,dim_wv)\n",
        "          wv_i = wv_i.mean(axis = 0)\n",
        "          wv_j = wv_j.mean(axis = 0)\n",
        "          val = np.dot(wv_i,wv_j)/(np.linalg.norm(wv_i)*np.linalg.norm(wv_j))\n",
        "          # W[start1+i][start2+j] = val\n",
        "          W[start2+j][start1+i] = val\n",
        "\n",
        "  \n",
        "  col_sum = W.sum(axis = 0, keepdims = True)\n",
        "  col_sum[col_sum == 0] = 1 # instead of dividing by zero, we leave it as is\n",
        "  W = W/col_sum\n",
        "  d = 0.85\n",
        "  I = np.eye(end)\n",
        "  R = np.linalg.inv(I - d*W)@(np.ones((end,1))*(1-d)/end)\n",
        "  result = []\n",
        "  for i in range(len(nouns)):\n",
        "    noun = nouns[i]\n",
        "    start,end = idx[i]\n",
        "    if start == end:  # no synsets for the noun were available\n",
        "      best_ss = 'None'\n",
        "    else:\n",
        "      best_ss = wordnet.synsets(noun)[np.argmax(R[start:end])]\n",
        "      best_ss = best_ss.name()\n",
        "    result.append(best_ss)\n",
        "  return result"
      ],
      "metadata": {
        "id": "0BD6TTaQ3GyB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YYvXG50YjcBp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "F0NtAWElFn6j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "087c7a6f-1d45-4359-b96a-c92cdae2f680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        0              1              2\n",
              "Noun            authority  investigation       evidence\n",
              "MFS        authority.n.01     probe.n.01  evidence.n.01\n",
              "WFS        authority.n.01     probe.n.01  evidence.n.01\n",
              "Ex-Lesk       agency.n.01     probe.n.01  evidence.n.03\n",
              "Page-Rank  authority.n.01     probe.n.01  evidence.n.03"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11607701-6093-492b-99b9-db76128f3cda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Noun</th>\n",
              "      <td>authority</td>\n",
              "      <td>investigation</td>\n",
              "      <td>evidence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MFS</th>\n",
              "      <td>authority.n.01</td>\n",
              "      <td>probe.n.01</td>\n",
              "      <td>evidence.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WFS</th>\n",
              "      <td>authority.n.01</td>\n",
              "      <td>probe.n.01</td>\n",
              "      <td>evidence.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ex-Lesk</th>\n",
              "      <td>agency.n.01</td>\n",
              "      <td>probe.n.01</td>\n",
              "      <td>evidence.n.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Page-Rank</th>\n",
              "      <td>authority.n.01</td>\n",
              "      <td>probe.n.01</td>\n",
              "      <td>evidence.n.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11607701-6093-492b-99b9-db76128f3cda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11607701-6093-492b-99b9-db76128f3cda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11607701-6093-492b-99b9-db76128f3cda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def tag(sentence):\n",
        "  sentence = preprocess(sentence)\n",
        "  \n",
        "  MFS = []\n",
        "  WFS = []\n",
        "  ExtendedLesk = []\n",
        "\n",
        "  nouns = []\n",
        "  \n",
        "  for (word,pos) in sentence:\n",
        "    if pos[0] != 'N': # only do nouns\n",
        "      continue\n",
        "    \n",
        "    nouns.append(word)  # for page rank\n",
        "\n",
        "    mfs = 'None'\n",
        "    if word in word_to_synset_freq:\n",
        "      ss_freq = word_to_synset_freq[word]\n",
        "      (maxsofar, best_ss) = (0, 'None')\n",
        "      for ss in ss_freq:\n",
        "        if ss_freq[ss] > maxsofar:\n",
        "          maxsofar = ss_freq[ss]\n",
        "          best_ss = ss\n",
        "      mfs = best_ss\n",
        "    MFS.append(mfs)\n",
        "    \n",
        "\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if len(synsets) == 0:\n",
        "      WFS.append('None')\n",
        "      ExtendedLesk.append('None')\n",
        "      continue\n",
        "\n",
        "    wfs = synsets[0]\n",
        "    context = set([w for (w,p) in sentence if w != word])\n",
        "    ex_lesk = extended_lesk(synsets, context)\n",
        "\n",
        "    WFS.append(wfs.name())\n",
        "    ExtendedLesk.append(ex_lesk.name())\n",
        "  \n",
        "  PageRank = pagerank(nouns, use_wv = False)\n",
        "\n",
        "  return nouns, MFS, WFS, ExtendedLesk, PageRank\n",
        "\n",
        "tagged_result = tag(\"The authorities said an investigation produced no evidence\")\n",
        "pd.DataFrame(tagged_result, index=['Noun', 'MFS', 'WFS', 'Ex-Lesk', 'Page-Rank'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The authorities said an investigation produced no evidence\n",
        "# wordnet.synset('authority.n.01').definition()\n",
        "for ss in tagged_result[3]:\n",
        "  print(ss, wordnet.synset(ss).definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKnm7jYEQe_-",
        "outputId": "f6e482f0-c60d-46bb-a639-cea2752438c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agency.n.01 an administrative unit of government\n",
            "probe.n.01 an inquiry into unfamiliar or questionable activities\n",
            "evidence.n.03 (law) all the means by which any alleged matter of fact whose truth is investigated at judicial trial is established or disproved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_semcor(sentence):\n",
        "  sentence = preprocess_from_semcor(sentence)\n",
        "  \n",
        "  MFS = []\n",
        "  WFS = []\n",
        "  ExtendedLesk = []\n",
        "  correct_lesk = 0\n",
        "  correct_pgrank = 0\n",
        "  correct_wfs = 0\n",
        "  correct_mfs = 0\n",
        "  total = 0\n",
        "  \n",
        "  nouns = []\n",
        "  true_ss = []\n",
        "\n",
        "  for (word,pos, true_synset) in sentence:\n",
        "    if pos[0] != 'N': # only do nouns\n",
        "      continue\n",
        "    \n",
        "    total += 1\n",
        "\n",
        "    mfs = 'None'\n",
        "    if word in word_to_synset_freq:\n",
        "      ss_freq = word_to_synset_freq[word]\n",
        "      (maxsofar, best_ss) = (0, 'None')\n",
        "      for ss in ss_freq:\n",
        "        if ss_freq[ss] > maxsofar:\n",
        "          maxsofar = ss_freq[ss]\n",
        "          best_ss = ss\n",
        "      mfs = best_ss\n",
        "    MFS.append(mfs)\n",
        "    correct_mfs += (mfs == true_synset)\n",
        "    \n",
        "\n",
        "    nouns.append(word)  # for page rank\n",
        "    true_ss.append(true_synset)\n",
        "\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if len(synsets) == 0:\n",
        "      WFS.append('None')\n",
        "      ExtendedLesk.append('None')\n",
        "      continue\n",
        "\n",
        "    wfs = synsets[0]\n",
        "    context = set([w for (w,p,s) in sentence if w != word])\n",
        "    ex_lesk = extended_lesk(synsets, context)\n",
        "\n",
        "    WFS.append(wfs.name())\n",
        "    ExtendedLesk.append(ex_lesk.name())\n",
        "    correct_lesk += (true_synset == ex_lesk.name())\n",
        "    correct_wfs += (true_synset == wfs.name())\n",
        "\n",
        "  PageRank = pagerank(nouns, use_wv = True)\n",
        "  for pgrank,true_synset in zip(PageRank, true_ss):\n",
        "    correct_pgrank += (true_synset == pgrank)\n",
        "  # print(correct_lesk,correct_wfs,total)\n",
        "  return true_ss, MFS, WFS, ExtendedLesk, PageRank, (total, correct_mfs, correct_wfs, correct_lesk, correct_pgrank)\n",
        "\n",
        "_ = tag_semcor(semcor.tagged_sents(tag = 'both')[1])\n",
        "__ = list(zip(_[0], _[1], _[2], _[3], _[4]))\n",
        "__.append(_[5])\n",
        "pd.DataFrame(__, columns=['true', 'MFS', 'WFS', 'Ex-Lesk', 'Page-Rank'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "0t_9RRGtWUKr",
        "outputId": "f1d816fa-28af-4c2e-c774-90bd82397d93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                true               MFS               WFS           Ex-Lesk  \\\n",
              "0          jury.n.01         jury.n.01         jury.n.01         jury.n.01   \n",
              "1          term.n.02         term.n.02         term.n.01         term.n.05   \n",
              "2           end.n.02          end.n.02          end.n.01         goal.n.01   \n",
              "3   presentment.n.01  presentment.n.01  presentment.n.01  presentment.n.01   \n",
              "4         group.n.01        group.n.01        group.n.01        group.n.01   \n",
              "5       mission.n.03       charge.n.02       charge.n.01       charge.n.03   \n",
              "6      election.n.01     election.n.01     election.n.01     election.n.02   \n",
              "7        praise.n.01       praise.n.01       praise.n.01       praise.n.01   \n",
              "8        thanks.n.01       thanks.n.01       thanks.n.01       thanks.n.01   \n",
              "9      location.n.01     location.n.01     location.n.01     location.n.01   \n",
              "10       manner.n.01       manner.n.01       manner.n.01       manner.n.01   \n",
              "11     election.n.01     election.n.01     election.n.01     election.n.02   \n",
              "12                12                11                 9                 7   \n",
              "\n",
              "           Page-Rank  \n",
              "0          jury.n.01  \n",
              "1          term.n.01  \n",
              "2           end.n.02  \n",
              "3   presentment.n.01  \n",
              "4         group.n.03  \n",
              "5        charge.n.03  \n",
              "6      election.n.03  \n",
              "7        praise.n.02  \n",
              "8        thanks.n.01  \n",
              "9      location.n.04  \n",
              "10       manner.n.01  \n",
              "11     election.n.02  \n",
              "12                 5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-730cb50a-400f-4956-863e-e6f008a929fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true</th>\n",
              "      <th>MFS</th>\n",
              "      <th>WFS</th>\n",
              "      <th>Ex-Lesk</th>\n",
              "      <th>Page-Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jury.n.01</td>\n",
              "      <td>jury.n.01</td>\n",
              "      <td>jury.n.01</td>\n",
              "      <td>jury.n.01</td>\n",
              "      <td>jury.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>term.n.02</td>\n",
              "      <td>term.n.02</td>\n",
              "      <td>term.n.01</td>\n",
              "      <td>term.n.05</td>\n",
              "      <td>term.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>end.n.02</td>\n",
              "      <td>end.n.02</td>\n",
              "      <td>end.n.01</td>\n",
              "      <td>goal.n.01</td>\n",
              "      <td>end.n.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>presentment.n.01</td>\n",
              "      <td>presentment.n.01</td>\n",
              "      <td>presentment.n.01</td>\n",
              "      <td>presentment.n.01</td>\n",
              "      <td>presentment.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>group.n.01</td>\n",
              "      <td>group.n.01</td>\n",
              "      <td>group.n.01</td>\n",
              "      <td>group.n.01</td>\n",
              "      <td>group.n.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mission.n.03</td>\n",
              "      <td>charge.n.02</td>\n",
              "      <td>charge.n.01</td>\n",
              "      <td>charge.n.03</td>\n",
              "      <td>charge.n.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>election.n.01</td>\n",
              "      <td>election.n.01</td>\n",
              "      <td>election.n.01</td>\n",
              "      <td>election.n.02</td>\n",
              "      <td>election.n.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>praise.n.01</td>\n",
              "      <td>praise.n.01</td>\n",
              "      <td>praise.n.01</td>\n",
              "      <td>praise.n.01</td>\n",
              "      <td>praise.n.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>thanks.n.01</td>\n",
              "      <td>thanks.n.01</td>\n",
              "      <td>thanks.n.01</td>\n",
              "      <td>thanks.n.01</td>\n",
              "      <td>thanks.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>location.n.01</td>\n",
              "      <td>location.n.01</td>\n",
              "      <td>location.n.01</td>\n",
              "      <td>location.n.01</td>\n",
              "      <td>location.n.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>manner.n.01</td>\n",
              "      <td>manner.n.01</td>\n",
              "      <td>manner.n.01</td>\n",
              "      <td>manner.n.01</td>\n",
              "      <td>manner.n.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>election.n.01</td>\n",
              "      <td>election.n.01</td>\n",
              "      <td>election.n.01</td>\n",
              "      <td>election.n.02</td>\n",
              "      <td>election.n.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-730cb50a-400f-4956-863e-e6f008a929fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-730cb50a-400f-4956-863e-e6f008a929fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-730cb50a-400f-4956-863e-e6f008a929fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "TaYJI2h-JU5T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total, mfs, wfs, lesk, pgrank = 0,0,0,0,0\n",
        "\n",
        "true_list = []\n",
        "mfs_list = []\n",
        "wfs_list = []\n",
        "lesk_list = []\n",
        "pgrank_list = []\n",
        "for i in range(10000,15000):\n",
        "  result = tag_semcor(corpus[i])\n",
        "  (t, m, w, l, p) = result[5]\n",
        "  total += t\n",
        "  mfs += m\n",
        "  wfs += w\n",
        "  lesk += l\n",
        "  pgrank += p\n",
        "  true_list += result[0]\n",
        "  mfs_list += result[1]\n",
        "  wfs_list += result[2]\n",
        "  lesk_list += result[3]\n",
        "  pgrank_list += result[4]\n",
        "  if i%1000 == 0:\n",
        "    print(i)\n",
        "# print(total, mfs/total, wfs/total, lesk/total, pgrank/total)\n",
        "\n",
        "_ = list()\n",
        "_.append(sklearn.metrics.precision_recall_fscore_support(true_list, mfs_list, average = 'weighted', zero_division = 0))\n",
        "_.append(sklearn.metrics.precision_recall_fscore_support(true_list, wfs_list, average = 'weighted', zero_division = 0))\n",
        "_.append(sklearn.metrics.precision_recall_fscore_support(true_list, lesk_list, average = 'weighted', zero_division = 0))\n",
        "_.append(sklearn.metrics.precision_recall_fscore_support(true_list, pgrank_list, average = 'weighted', zero_division = 0) )\n",
        "\n",
        "df = pd.DataFrame(_, index=['MFS', 'WFS', 'Ex-Lesk', 'Page-Rank'], columns = ['precision', 'recall', 'fscore', 'Accuracy'])\n",
        "df['Accuracy'] = [mfs/total, wfs/total, lesk/total, pgrank/total]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "_9Kh33YjdH-d",
        "outputId": "0eacd3c2-059b-4c5c-8d03-deca8057bb1e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           precision    recall    fscore  Accuracy\n",
              "MFS         0.472077  0.535379  0.478419  0.535379\n",
              "WFS         0.705983  0.760303  0.711647  0.748562\n",
              "Ex-Lesk     0.676971  0.619534  0.614263  0.607793\n",
              "Page-Rank   0.657321  0.434915  0.477281  0.434915"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ea86cee-d18e-493b-8b6f-5fd0f29cbf66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>fscore</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MFS</th>\n",
              "      <td>0.472077</td>\n",
              "      <td>0.535379</td>\n",
              "      <td>0.478419</td>\n",
              "      <td>0.535379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WFS</th>\n",
              "      <td>0.705983</td>\n",
              "      <td>0.760303</td>\n",
              "      <td>0.711647</td>\n",
              "      <td>0.748562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ex-Lesk</th>\n",
              "      <td>0.676971</td>\n",
              "      <td>0.619534</td>\n",
              "      <td>0.614263</td>\n",
              "      <td>0.607793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Page-Rank</th>\n",
              "      <td>0.657321</td>\n",
              "      <td>0.434915</td>\n",
              "      <td>0.477281</td>\n",
              "      <td>0.434915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ea86cee-d18e-493b-8b6f-5fd0f29cbf66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ea86cee-d18e-493b-8b6f-5fd0f29cbf66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ea86cee-d18e-493b-8b6f-5fd0f29cbf66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Labels = list(set(true_list).union(set(lesk_list)).union(set(pgrank_list)))"
      ],
      "metadata": {
        "id": "Zs1xDC3IjN2J"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqUC9kz7jolq",
        "outputId": "e2b025ff-b094-4fea-b0e2-d61fc87732e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10466"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_lesk = sklearn.metrics.confusion_matrix(true_list, lesk_list, labels = Labels)\n",
        "cm_pgrank = sklearn.metrics.confusion_matrix(true_list, pgrank_list, labels = Labels)"
      ],
      "metadata": {
        "id": "gyvT-tAggzlZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.fill_diagonal(cm_lesk, 0)\n",
        "np.fill_diagonal(cm_pgrank, 0)"
      ],
      "metadata": {
        "id": "ouTlAYu6j2gR"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_lesk = np.where(cm_lesk>25)\n",
        "conf_pgrank = np.where(cm_pgrank>70)"
      ],
      "metadata": {
        "id": "5thm3JCLn2-s"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in zip(conf_lesk[0], conf_lesk[1]):\n",
        "  print(Labels[a], Labels[b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbAPA4jdnjFU",
        "outputId": "9b7dbc13-761b-459d-8f97-5800f831e2ad"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day.n.01 day.n.03\n",
            "united_states.n.01 united_states_government.n.01\n",
            "time.n.01 time.n.05\n",
            "time.n.03 time.n.05\n",
            "None one.n.01\n",
            "None fluorine.n.01\n",
            "act.n.01 act.n.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in zip(conf_pgrank[0], conf_pgrank[1]):\n",
        "  print(Labels[a], Labels[b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuQNwQ30orDk",
        "outputId": "5447f335-6a02-447d-8b35-d8525ce06709"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person.n.01 person.n.03\n",
            "person.n.01 person.n.02\n",
            "group.n.01 group.n.03\n",
            "group.n.01 group.n.02\n",
            "location.n.01 location.n.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(ss,ss.definition()) for ss in wordnet.synsets(\"bank\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wgCTUF7Zd3u",
        "outputId": "1a4d3750-8ad9-4bc9-8bb3-a1723e7f6dc8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Synset('bank.n.01'),\n",
              "  'sloping land (especially the slope beside a body of water)'),\n",
              " (Synset('depository_financial_institution.n.01'),\n",
              "  'a financial institution that accepts deposits and channels the money into lending activities'),\n",
              " (Synset('bank.n.03'), 'a long ridge or pile'),\n",
              " (Synset('bank.n.04'),\n",
              "  'an arrangement of similar objects in a row or in tiers'),\n",
              " (Synset('bank.n.05'),\n",
              "  'a supply or stock held in reserve for future use (especially in emergencies)'),\n",
              " (Synset('bank.n.06'),\n",
              "  'the funds held by a gambling house or the dealer in some gambling games'),\n",
              " (Synset('bank.n.07'),\n",
              "  'a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force'),\n",
              " (Synset('savings_bank.n.02'),\n",
              "  'a container (usually with a slot in the top) for keeping money at home'),\n",
              " (Synset('bank.n.09'),\n",
              "  'a building in which the business of banking transacted'),\n",
              " (Synset('bank.n.10'),\n",
              "  'a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)'),\n",
              " (Synset('bank.v.01'), 'tip laterally'),\n",
              " (Synset('bank.v.02'), 'enclose with a bank'),\n",
              " (Synset('bank.v.03'), 'do business with a bank or keep an account at a bank'),\n",
              " (Synset('bank.v.04'), 'act as the banker in a game or in gambling'),\n",
              " (Synset('bank.v.05'), 'be in the banking business'),\n",
              " (Synset('deposit.v.02'), 'put into a bank account'),\n",
              " (Synset('bank.v.07'), 'cover with ashes so to control the rate of burning'),\n",
              " (Synset('trust.v.01'), 'have confidence or faith in')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}